## 原理 ##
### 什么是线性回归 ###
y~X 

	y=ΘX

### 学会线性回归的一般化模型的数学表示 ###
X(1...n)  指的是X有1...n个输入

		1		 0
	Y = ΣΘ^nX^n+Θ^0=Σ^nX^n
		n        n

	Θ=[Θ^0,...,Θ^n]
	X=[X^0,...,X^n]
	Y=ΘX

### 最小二乘法 ###
#### 理解通过向量运算进行参数求解过程 ####

### 最小二乘法模型 ###
	
	Y=ΘX   					<----函数模型
		1
	L=----(ΘX-Y)^T(ΘX-Y)    <----损失函数(求导)
		2
	Θ=(X^TX)^-1X^TY			<----参数计算
	
### 梯度下降 ###
梯度下降可以使用于线性回归和非线性回归

#### 直接计算的问题 ####

	Y=ΘX   					<----矩阵是否满秩
		1
	L=----(ΘX-Y)^T(ΘX-Y)    
		2
	Θ=(X^TX)^-1X^TY			运算性能

公式参数视频


随着数据越来越大，使用最小二乘法会导致效率越来越慢，所以使用梯度下降来优化学习效率


