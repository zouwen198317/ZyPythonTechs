## 分类与回归 ##

- 回归
> 目标值连续，值可以在某个区间内取任意数

- 分类
> 目标值离散,0,1,2(类别)

## 回归算法 ##

期末成绩: 0.7x考试成绩+0.3x平时成绩

西瓜好坏: 0.2x色泽+0.5x根蒂+0.3x敲声

- 线性回归
> 寻找一种能预测的趋势

- 线性关系
> 在二维中,是直线的关系

> 三维:特征,目标值,数据在一个平面当中

### 直线的方程 ###
#### y = kx ####
房屋价格预测:
y = 2.1*房子的面积 =>

y = 2.1 * 80 = 168 

## 线性关系的定义 ##
### y = kx+b ###
### y = wx+b ###
加b的原因是为了使对于单个特征的情况更加通用

### 多个特征 ###
k1房子面积+k2房子面积+b

w1房子面积+w2房子面积+b

## 线性关系模型 ##
一个通过属性的线性组合来进行预测的函数

f(x)=w1x2+w2x2+...wdxd+b

w 为权重, b为偏置项,可以理解为w0x1

## 线性回归 ##
定义:线性回归通过一个或者多个自变量(特征)与因变量(目标)之间进行建模的回归分析。其中可以为一个或多个自变量之间的线性组合

一元线性回归:涉及到的变量只有一个

多元线性回归:涉及到的变量两个或两个以上


通用公式:

		h(w) = w0+w1x1+w2x2+... 
			 = wT(转置)x
其中w,x为矩阵:

		w = (w1,
			 w2,
			 w3) => ()更换为大括号
		x = (1,
			 x1,
			 x2) => ()更换为大括号

线性回归是通过找到属性和权重的一种组合来预测结果


# 矩阵 #
必须是二维，满足了特定的运算需求
## 矩阵乘法 ##
(m行,l列)*(l行,n列) = (m行,n列)

	特征值   		权重 		 				目标值
	[[1,2,3,4]](1,4) [[2],[2],[2],[2]](4,1)   一个样本应该是一个值(1,1)



回归: 迭代的算法 


## 损失函数(误差大小) ##

yi为第i个训练样本的真实值

hw(xi)为第9个训练样本特征值组合预测函数



总损失定义:

最小二乘法(损失越小越好)

## <<统计学习方法>> 迭代过程 ##

-  算法
> 线性回归 

-  策略(损失函数) 
> 误差平方和(最小二乘法)

-  优化 
> 寻找最优化的W的值  ==>> 正规方程，梯度下降


如何去求模型当中的W，使得损失最小?

目的是找到最小损失对应的W值

求解:w = (XTX)-1XTy

X 为特征值矩阵， y为目标值矩阵

	  特征值(X)      目标值(Y)		w
	[[1,2,3,4]		[[200]   	[[]
	[3,4,5,6]		[150]		[]
	[20,19,3,4]		[300]		[]
	[6,5,8,9]]		[260]]		[]]

-1为矩阵的逆,x*? =
 
	[1,0,0,0
	 0,1,0,0
	 0,0,1,0
	 0,0,0,1]

?就是x的逆

单位矩阵:从左上角到右下角全部是1(斜着)


## 最小二乘法之正规方程 ##
有的时候会求解不到w,不通用

## 最小二乘法之梯度下降 ##
只需要记住参数即可

学习率x方向

学习率影响下降的快慢

沿着函数下降的方向找，最后就能找到山谷的最低点，然后更新W值

w 是随机初始的


## api ##
sklearn.linear_model.LinearRegression 正规方程(普通最小二乘线性回归)

sklearn.linear_model.SGDRegressor 梯度下降(通过使用SGD最小线性模型)

## scikit-learn优缺点 ##
  优点: 封装好,建立模型简单,预测简单

  缺点: 算法的过程,有些参数都在算法API内部优化

## tensorflow:封装高低 ##
自己实现线性回归

示例：
波士顿房价数据集预测

http://t.cn/RfHTAgY
数据集地址
https://archive.ics.uci.edu/ml/datasets/Housing

示例代码:

Examples

	>>> import numpy as np
	>>> from sklearn.model_selection import train_test_split
	>>> X, y = np.arange(10).reshape((5, 2)), range(5)
	>>> X
	array([[0, 1],
	       [2, 3],
	       [4, 5],
	       [6, 7],
	       [8, 9]])
	>>> list(y)
	[0, 1, 2, 3, 4]
	
	>>> X_train, X_test, y_train, y_test = train_test_split(
	...     X, y, test_size=0.33, random_state=42)
	...
	>>> X_train
	array([[4, 5],
	       [0, 1],
	       [6, 7]])
	>>> y_train
	[2, 0, 3]
	>>> X_test
	array([[2, 3],
	       [8, 9]])
	>>> y_test
	[1, 4]
	
	>>> train_test_split(y, shuffle=False)
	[[0, 1, 2], [3, 4]]


## 回归性能评估 ##
远方误差(mean squared error)MSE